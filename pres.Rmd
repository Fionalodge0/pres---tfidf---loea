---
title: "tf-idf-pres-LAEA"
author: "Fiona R Lodge"
date: "5/12/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction and Use Case

During my internship at Securian, I was given a dataset which contained medical conditions (as text) for life insurance applicants.  In the exploratory phase, I used the tf-idf statistic to extract medical conditions characteristic to each underwriting class.  As an example, diabetes may be a condition characteristic to a  underwriting class associated with a higher risk.  

Most commonly the tf-idf statistic is used for tasks involved in information retrieval, but is also used as a text vectorization tool for predictive modeling.  


## The First Dataset

For the next few examples, I will be using the text generated from the Wikipedia articles on baseball and cricket. Although these sports are considered similar, the tf-idf should pull words that are characteristic to each sport.  

```{r tables, message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(tidytext)
library(jpeg)
library(kableExtra)
library(caret)
library(tm)


cricket <- read.delim2('C://Users//Owner//Documents//Github//tf_idfpresentationonbaseballandcricket//cricket - Wikipedia.txt', header = FALSE, fill = FALSE, col.names = 'cricket.words', stringsAsFactors = FALSE)
baseball <- read.delim2('C://Users//Owner//Documents//Github//tf_idfpresentationonbaseballandcricket//Baseball - Wikipedia.txt', fill = FALSE, col.names = 'baseball.words', stringsAsFactors = FALSE)

pal <- c("#4F628E","#7887AB", "#2E4272", "#AA8439")
```

```{r image, echo=FALSE, fig.align='center', fig.width=0.25}
knitr::include_graphics('C://Users//Owner//Documents//Github//tf_idfpresentationonbaseballandcricket//baseball_cricket.PNG')
```

The data was tokenized by single words using the `unnest_tokens` tool from the tidytext package.  A tokenization of the sentence 'Baseball is a bat-and-ball game' would be 'Baseball', 'is', 'a', 'bat-and-ball', 'game'.  

```{r tokenized_data, message=FALSE, warning=FALSE}
# tokenize
baseball.tokenized <- 
  baseball %>%
  unnest_tokens(output = word, input = baseball.words, token = 'words') %>%
  mutate(sport = 'baseball') %>%
  select(sport, word) # just reorders the data

head(baseball.tokenized)
```

The same was done for the text data for the sport of cricket and row-binded into one dataframe.  Below are distributional words for each sport.

```{r tokenized, include=FALSE}
# tokenize
cricket.tokenized <- 
  cricket %>%
  unnest_tokens(word, cricket.words) %>%
  mutate(sport = 'cricket')

# combine
sports <- bind_rows(baseball.tokenized, cricket.tokenized)

wordfreq <-
  sports %>%
  group_by(sport, word) %>%
  summarise(N = n()) %>%
  mutate(total = sum(N)) %>%
  ungroup()

wordfreq %>%
  mutate(freq = N/total) %>%
  arrange(desc(freq)) %>%
  mutate(word = factor(word, levels = unique(word))) %>%
  group_by(sport) %>%
  top_n(15, freq) %>%
  ungroup %>%
  ggplot(aes(word, freq, fill = sport)) + 
  scale_fill_manual(values = pal[c(1,4)])+
  geom_col(show.legend = FALSE) +
  facet_wrap(~sport, dir = 'v', scales = 'free') 
```

## The Distribution of text data

Text data often follows a lognormal (?) distribution, mainly because the english language repeatly uses the same words, such as 'is', 'the', 'a', etc.  Below is the plot of the proportional distributions of words from both the baseball and cricket text.  


```{r dist_plot}
wordfreq <-
  sports %>%
  group_by(sport, word) %>%
  summarise(N = n()) %>%
  mutate(total = sum(N)) %>%
  ungroup()

wordfreq %>%
  mutate(freq = N/total) %>%
  arrange(desc(freq)) %>%
  mutate(word = factor(word, levels = unique(word))) %>%
  group_by(sport) %>%
  top_n(100, freq) %>%
  ungroup %>%
  ggplot(aes(word, freq, fill = sport)) + 
  scale_fill_manual(values = pal[c(1,4)])+
  geom_col(show.legend = FALSE) +
  geom_density() + 
  facet_wrap(~sport, dir = 'v', scales = 'free') 

# Total for both together
totals <- sports %>% group_by(word) %>% summarize(N= n()) %>% arrange(desc(N)) %>% ungroup

sum <- sum(totals$N[1:6])
# totals[1:6, 'word']
```

In the combined dataframe, the words 'the', 'of', 'a', 'and', 'in', 'to' occur around 20% of the time!  These type of words are often referred to as 'stop words' and sometimes removed in the preprocessing step.  Sometimes, it may be appropriate to use frequency counts as a vector representation for text, but often it may not be an accurate depictor of the textual features.  

## Forming the idf with the natural logarithm

Frequency counts don't really tell us much about the sport of baseball and cricket, and we need to be able to differentiate characteristic words from noise.  The idf (inverse document frequency) achieves just this.  The more often a word appears in a document, the less weight it will receive.   

```{r natural_logarithm_plot}
log.df <- cbind.data.frame('x' = seq(0, 1, by = 0.001), y = log(1/seq(0, 1, by = 0.001)))

ggplot(log.df, aes(x = x, y = y)) + geom_line() + xlab('Total number of Documents/Number of Documents Containing That Word') + ylab('log(x)') + ggtitle('IDF')
```

For example, since the word 'the' occurs in both documents, `idf: log(2/2) = 0`. However, since the word 'cricket' occurs in only one of the documents, `idf: log(2/1) = 0.69`.  Hence, the words that are unique to each document will recieve a higher weight than those that occur frequently.  

## The tf-idf statistic

Term frequency is still important, i.e. if baseball occurs once in a document it may not be as much about baseball as a document that contains the word baseball 50 times.  So, we have arrived at the full version of the tf-idf statistic:

Insert here

Variations include:
- addition of 1 in the denominator to avoid division by zero
- squaring of the statistic in practice (?)

## Using the tf-idf statistic on the cricket/baseball example

Below are the results of calculating the `tf-idf` on the cricket/baseball data. 

```{r tf_idf_basball_data}
sports_tfidf <- 
  wordfreq %>%
  bind_tf_idf(term = word, document = sport, n = N)

sports_tfidf %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  group_by(sport) %>%
  top_n(15, tf_idf) %>%
  ungroup %>%
  ggplot(aes(word, tf_idf, fill = sport)) + 
  scale_fill_manual(values = pal[c(1,4)])+
  geom_col(show.legend = FALSE) +
  facet_wrap(~sport, scales = 'free') + 
  coord_flip() 
```

This is much more informative!  For example, I now know that bowler is to cricket as pitcher is to baseball.  From the 'american' and 'mlb', I can guess that baseball is popular in America, but 'icc' and 'nations' suggests that cricket is more popular as an international sport.  From an exploratory sense, this is much more informative.  

## Briefly on tf-idf for Information Retrieval

